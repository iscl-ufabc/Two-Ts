{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Validação das Expressões Two-Ts.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/jcheong0428/c16146b386ea60fab888b56e8e5ee747/openface_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMhPBvnrARcd"
      },
      "source": [
        "# *Two-Ts*: Reprodução de Expressões Faciais em Cabeça Robótica com Tecnologia 3D\n",
        "\n",
        "Trabalho de Mestrado em Ciência da Computação da Universidade Federal do ABC (UFABC).\n",
        "\n",
        "Discente: Tamires dos Santos.\n",
        "\n",
        "Orientador: Wagner Tanaka Botelho.\n",
        "\n",
        "Bolsas Recebidas:\n",
        "+ Treinamento Técnico (TT-3) do Programa PIPE da Fundação de Amparo à Pesquisa do Estado de São Paulo - FAPESP, com o processo número 2019/08079-1, pela  Startup NTU Software Technology do Projeto PIPE Fase 2 (Processo Número: 2018/04306-0) no período de Junho/2019 a Maio/2020;\n",
        "+ Bolsa de mestrado da Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) no período de Outubro/2020 a Fevereiro/2021.\n",
        "\n",
        "\n",
        "\n",
        "Data de modificação: Julho/2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiVMHhCOMzyq"
      },
      "source": [
        "# Sistema de validação das Expressões da *Two-Ts*\n",
        "\n",
        "\n",
        "Este notebook usa o projeto de código aberto [OpenFace](https://github.com/TadasBaltrusaitis/OpenFace), de Tadas Baltrusaitis, para detectar a partir de uma face, as Unidades de Ações (UAs) baseadas no FACS criada por [Paul Ekman](https://www.paulekman.com/) em  parceria com Wallace Friesen. \n",
        "\n",
        "Além da instruções presentes no github do OpenFace, também foi utilizado como base o artigo e notebbok criado por Jin Hyun Cheong (https://towardsdatascience.com/how-to-extract-facial-expressions-head-pose-and-gaze-from-any-youtube-video-2aa6590c2bb6).\n",
        "\n",
        "O objetivo do código é realizar a validação das expressões faciais, durante a reprodução das seis emoções básicas e universais, na face da *Two-Ts* virtual e real, em comparação com a da discente Tamires dos Santos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlvZkuHc0ynn"
      },
      "source": [
        "### Instalação do OpenFace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXBkyjI_GqtQ"
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "################# Install CUDA 10.0 #################\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update\n",
        "!wget  --no-clobber https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-10-0\n",
        "!wget --no-clobber http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "!apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "!apt-get update\n",
        "#######################################################\n",
        "\n",
        "################# Install OpenFace #################\n",
        "git_repo_url = 'https://github.com/TadasBaltrusaitis/OpenFace.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "!git clone -q --depth 1 $git_repo_url\n",
        "#######################################################\n",
        "\n",
        "################# Install other packages #################\n",
        "!wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz\n",
        "!tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install build-essential \n",
        "!sudo apt-get install g++-8\n",
        "#######################################################\n",
        "\n",
        "# Finishing the installation\n",
        "!cd OpenFace && bash ./download_models.sh && sudo bash ./install.sh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8QW173G15ev"
      },
      "source": [
        "### Selecionar imagens \n",
        "\n",
        "Localiza as imagens e extrae os dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdVSEBT8XdVn"
      },
      "source": [
        "# Create folder to store data\n",
        "!rm -rf processed\n",
        "\n",
        "!./OpenFace/build/bin/FaceLandmarkImg -f virtual.jpg -out_dir processed -of dataImage1   #Two-Ts virtual\n",
        "!./OpenFace/build/bin/FaceLandmarkImg -f real.jpg -out_dir processed -of dataImage2  #Two-Ts real\n",
        "!./OpenFace/build/bin/FaceLandmarkImg -f tamires.png -out_dir processed -of dataImage3  #Discente Tamires"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z1nUfT22bMH"
      },
      "source": [
        "###Carregar os dados de cada imagem\n",
        "\n",
        "Será carregado os dados das imagens em Pandas, renomeando as colunas para eliminar espaços vazios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax8JJ3ayfIyO"
      },
      "source": [
        "import pandas as pd, seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "df1 = pd.read_csv('processed/dataImage1.csv')\n",
        "df1.columns = [col.replace(\" \", \"\") for col in df1.columns]\n",
        "\n",
        "df2 = pd.read_csv('processed/dataImage2.csv')\n",
        "df2.columns = [col.replace(\" \", \"\") for col in df2.columns]\n",
        "\n",
        "df3 = pd.read_csv('processed/dataImage3.csv')\n",
        "df3.columns = [col.replace(\" \", \"\") for col in df3.columns]\n",
        "\n",
        "print(df1)\n",
        "print(df2)\n",
        "print(df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPvbE8Tb3Dqv"
      },
      "source": [
        "### Plotar os resultados das UAs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXD88gVKCc85"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Function to read the column values of the AUs\n",
        "def valuesAUs(id_image):\n",
        "  au_values = []\n",
        "  au_list = ['01', '02', '04', '05', '06' ,'07', '09', '10', '12', '14', '15', '17', '20', '23', '25', '26' , '45']\n",
        "  \n",
        "  for i in range(0, len(au_list)):\n",
        "    x = 'AU'+ au_list[i] +\"_r\"\n",
        "    if id_image == 1:\n",
        "        au_values.append(df1[x][0])\n",
        "    if id_image == 2:\n",
        "      au_values.append(df2[x][0])\n",
        "    if id_image == 3:\n",
        "      au_values.append(df3[x][0])\n",
        "  \n",
        "  return au_values\n",
        "\n",
        "listName = ['UA1', 'UA2', 'UA4', 'UA5', 'UA6' ,'UA7', 'UA9', 'UA10', 'UA12', 'UA14', 'UA15', 'UA17', 'UA20', 'UA23', 'UA25', 'UA26' , 'UA45']\n",
        "\n",
        "#au_regex_pat = re.compile(r'^AU[0-9]+_r$')\n",
        "#au_columns1 = df1.columns[df1.columns.str.contains(au_regex_pat)]\n",
        "\n",
        "au_values1 = valuesAUs(1)\n",
        "au_values2 = valuesAUs(2)\n",
        "au_values3 = valuesAUs(3)\n",
        "\n",
        "image1 =  np.arange(len(au_values1))\n",
        "image2 = [i + 0.2 for i in image1]\n",
        "image3 = [i + 0.4 for i in image1]\n",
        "\n",
        "plt.bar(image1, au_values1, width=0.2, label = 'Two-Ts Virtual', edgecolor ='g', color = 'white')\n",
        "plt.bar(image2, au_values2, width=0.2, label = 'Two-Ts Real', color = 'gray')\n",
        "plt.bar(image3, au_values3, width=0.2, label = 'Tamires', color = 'black')\n",
        "plt.xticks([i for i in range(len(au_values1))], listName)\n",
        "plt.xticks(rotation=20)\n",
        "plt.legend()\n",
        "plt.gcf().set_size_inches(20, 5) \n",
        "plt.ylabel('Intensidade')\n",
        "plt.xlabel('Unidade de Ação')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
